# Duxiaoman-learn

数据智能领域优秀文章分享（持续更新中...)

   ### NLP方向

 - cosFormer：Rethinking Softmax in Attention 
 -PDF: https://arxiv.org/abs/2202.08791
   
 - Transformer Quality in Linear Time  
 -PDF: https://arxiv.org/abs/2202.10447
   
 - Contextual Representation Learning beyond Masked Language Modeling 
 -PDF:    http://wiki.duxiaoman-int.com/download/attachments/197406888/2204.04163.pdf?version=1&modificationDate=1652870758000&api=v2
 - cosFormer：Rethinking Softmax in Attention 
 -PDF: https://arxiv.org/abs/2202.08791
  
 - Pyramid-BERT: Reducing Complexity via Successive Core-set based Token Selection 
 -PDF: https://arxiv.org/pdf/2203.14380.pdf

 - Robust Lottery Tickets for Pre-trained Language Models 
 -PDF: https://aclanthology.org/2022.acl-long.157/
     
 - Compression of Generative Pre-trained Language Models via Quantization 
 -PDF: https://arxiv.org/pdf/2203.10705.pdf
      
 - Filter-enhanced MLP is All You Need for Sequential Recommendation	
 -PDF: https://arxiv.org/abs/2202.13556	
     
 - A Simple but Effective Pluggable Entity Lookup Table for Pre-trained Language Models	
 -PDF:    https://arxiv.org/pdf/2202.13392.pdf
      

 - Divide and Conquer: Text Semantic Matching with Disentangled Keywords and Intents  
 -PDF:https://arxiv.org/abs/2203.02898
 
 -  Training Data is More Valuable than You Think: A Simple and Effective Method by Retrieving from Training Data	 
 -PDF:    https://arxiv.org/abs/2203.08773
   
 -  BERT Learns to Teach: Knowledge Distillation with Meta Learning	
 -PDF: https://aclanthology.org/2022.acl-long.485/
   
 -  A Contrastive Framework for Learning Sentence Representations from Pairwise and Triple-wise Perspective in Angular Space	
 -PDF:    https://aclanthology.org/2022.acl-long.336.pdf
   
 -  LongT5: Efficient Text-To-Text Transformer for Long Sequences	
 -PDF: https://arxiv.org/abs/2112.07916
   
 -  Debiased Contrastive Learning of Unsupervised Sentence Representations	
 -PDF: https://arxiv.org/pdf/2205.00656.pdf
   
 -  DiffCSE: Difference-based Contrastive Learning for Sentence Embeddings	
 -PDF: https://aclanthology.org/2022.naacl-main.311.pdf
   
 -  Poolingformer: Long Document Modeling with Pooling Attention	
 -PDF: https://arxiv.org/pdf/2105.04371.pdf
   
 -  Dict-BERT: Enhancing Language Model Pre-training with Dictionary	
 -PDF: https://arxiv.org/pdf/2110.06490.pdf
   
 -  FactPEGASUS: Factuality-Aware Pre-training and Fine-tuning for Abstractive Summarization 
 -PDF: https://arxiv.org/abs/2205.07830
   
 -  Efficient Long-Text Understanding with Short-Text Models	
 -PDF: https://arxiv.org/pdf/2208.00748.pdf
   
 -  Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification	 
 -PDF:    https://aclanthology.org/2022.acl-long.158/
   
 -  ESimCSE: Enhanced Sample Building Method for Contrastive Learning of Unsupervised Sentence Embedding	 
 -PDF:    https://arxiv.org/abs/2109.04380
   
 -  CoDA: Contrast-enhanced and Diversity-promoting Data Augmentation for Natural Language Understanding	 
 -PDF:    https://openreview.net/forum?id=Ozk9MrX1hvA
   
 -  An Exploration of Hierarchical Attention Transformers for Efficient Long Document Classification	 
 -PDF:    https://arxiv.org/abs/2210.05529
 
 
      
   ### 因果推断方向

 - Introduction to Causal Inference from a Machine Learning Perspective
 -PDF: https://www.bradyneal.com/Introduction_to_Causal_Inference-Dec17_2020-Neal.pdf

- Quasi-Oracle Estimation of Heterogeneous Treatment Effects
-PDF: https://arxiv.org/pdf/1712.04912.pdf

- Orthogonal Random Forest for Causal Inference
-PDF: http://proceedings.mlr.press/v97/oprescu19a/oprescu19a.pdf

- Policy Learning with Observational Data
-PDF: https://arxiv.org/pdf/1702.02896.pdf

- Adapting Neural Networks for the Estimation of Treatment Effects
-PDF: https://proceedings.neurips.cc/paper/2019/file/8fb5f8be2aa9d6c64a04e3ab9f63feee-Paper.pdf

- Decision trees for uplift modeling with single and multiple treatments
-PDF: https://link.springer.com/content/pdf/10.1007/s10115-011-0434-0.pdf

- Estimation and Inference of Heterogeneous Treatment Effects using Random Forests
-PDF: https://arxiv.org/pdf/1510.04342.pdf

- Learning Counterfactual Representations for Estimating Individual Dose-Response Curves
-PDF: https://arxiv.org/abs/1902.00981

- Double/debiased machine learning for treatment and structural parameters 
-PDF: https://academic.oup.com/ectj/article/21/1/C1/5056401?login=true


### CV方向
 
 - Cluster Contrast for Unsupervised Person Re-Identification
 -PDF:https://arxiv.org/pdf/2103.11568.pdf ； 
 - Think Twice Before Detecting GAN-generated Fake Images from their Spectral Domain Imprints
 -PDF: https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Think_Twice_Before_Detecting_GAN-Generated_Fake_Images_From_Their_Spectral_CVPR_2022_paper.pdf；
 - Frequency Domain Model Augmentation for Adversarial Attack
 -PDF: https://arxiv.org/pdf/2207.05382.pdf；
 - Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs
 -PDF: https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Scaling_Up_Your_Kernels_to_31x31_Revisiting_Large_Kernel_Design_CVPR_2022_paper.pdf；
 - VToonify: Controllable High-Resolution Portrait Video Style Transfer
 -PDF: https://arxiv.org/pdf/2209.11224.pdf；
 - Anchor-Free Person Searc
 -PDF: https://openaccess.thecvf.com/content/CVPR2021/papers/Yan_Anchor-Free_Person_Search_CVPR_2021_paper.pdf.  
 - Text Detection, Tracking and Recognition in Video: A Comprehensive Survey
 -PDF:https://ieeexplore.ieee.org/abstract/document/7452620
 - An Efficient Training Approach for Very Large Scale Face Recognition
 -PDF:https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_An_Efficient_Training_Approach_for_Very_Large_Scale_Face_Recognition_CVPR_2022_paper.pdf
 - What Is Considered Complete for Visual Recognition?
 -PDF:https://www.researchgate.net/publication/351990384_What_Is_Considered_Complete_for_Visual_Recognition
 - Visual Recognition by Request
 -PDF:https://arxiv.org/abs/2207.14227
 - End-to-End Video Text Spotting with Transformer
 -PDF:https://ui.adsabs.harvard.edu/abs/2022arXiv220310539W/abstract
 - AdaFace: Quality Adaptive Margin for Face Recognition
 -PDF:https://arxiv.org/abs/2204.00964
 
 
